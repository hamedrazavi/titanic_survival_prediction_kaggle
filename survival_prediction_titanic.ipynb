{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic: Machine Learning from Disaster\n",
    "This is a kaggle competition where we will predict the survival of a subset of titanic passenters (test set), given a set of passengers with known survival (train set). For each passenger there exist several features, including Name, Age, Sex, Ticket number, Ticket class, etc. We follow these steps:\n",
    "\n",
    "1. Exploring the data\n",
    "2. Cleanig and feature selection\n",
    "3. Prediction models, cross-validation and prediction\n",
    "\n",
    "This kernel led to a kaggle submission accuracy of __0.82296__. For those who already have made submissions, the key points are summarized below:\n",
    "\n",
    "- Even though the cabin feature has many missing data, it can be replaced by 0, 1. 0 when cabin is NaN and 1 otherwise. We will see that there is a correlation between \n",
    "- Ticket column is usefull; there is a correlation between survival chance and prefix of the Ticket feature. \n",
    "- The key to get an score above 0.80 seems to be proper use of Ticket or Family clustering. I grouped passengers based on their ticket numbers (there are multiple individuals with the same ticket numbers!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries\n",
    "As the first step all neccessary libraries will be imported; this list will be updated as we are going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import ensemble, model_selection\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import and explore the data\n",
    "We import and explore the data; how many samples do we have, what are the attributes are, what are the missing data... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trData = pd.read_csv('train.csv')\n",
    "testData = pd.read_csv('test.csv')\n",
    "data_list = [trData, testData]\n",
    "trData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "We use describe() method to quickly get an overview of the features and the output ('Survived'). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the training data (trData), the average survival data is ~0.384, so only 342 passengers out of 891 (see below) passengers survived. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trData['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs: Distribution of the features\n",
    "Now we explore distribution of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAACFCAYAAABVEzPoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ad27400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sex\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(trData['Sex'])\n",
    "\n",
    "# Pclass \n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(trData['Pclass'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of samples in train set is:\", len(trData))\n",
    "print(\"-\"*45)\n",
    "print(\"The number of null (NaN) values in each column of the train set is:\")\n",
    "print(trData.isnull().sum())\n",
    "print(\"*\"*70)\n",
    "print(\"Total number of samples in test set is:\", len(testData))\n",
    "print(\"-\"*45)\n",
    "print(\"The number of null (NaN) values in each column of the train set is:\")\n",
    "print(testData.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    #data['Age'].fillna(trData['Age'].median(), inplace = True)\n",
    "    data['Embarked'].fillna(trData['Embarked'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of samples in train set is:\", len(trData))\n",
    "print(\"-\"*45)\n",
    "print(\"The number of null (NaN) values in each column of the train set is:\")\n",
    "print(trData.isnull().sum())\n",
    "print(\"*\"*70)\n",
    "print(\"Total number of samples in test set is:\", len(testData))\n",
    "print(\"-\"*45)\n",
    "print(\"The number of null (NaN) values in each column of the train set is:\")\n",
    "print(testData.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedData = pd.concat(objs=[trData, testData], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PclassVsFare = combinedData[['Pclass','Fare']].groupby(['Pclass'], as_index = False).mean()\n",
    "PclassVsFare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['Pclass'][testData['Fare'].isnull()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The passenger with missing class has a Pclass of 3 whose average Fare is 13.67 \n",
    "testData['Fare'].fillna(PclassVsFare.loc[2,'Fare'], inplace = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    data['Title'] = data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    data['Title'] = data['Title'].replace(['Lady', 'Sir', 'the Countess'], 'Royal')\n",
    "    data['Title'] = data['Title'].replace(['Ms', 'Mlle'], 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
    "    data['Title'] = data['Title'].replace(['Lady', 'Capt', 'Col',\n",
    "    'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    data['Nfamily'] = data['Parch'] + data['SibSp'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedData = pd.concat(objs=[trData, testData], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedData.loc[combinedData['Ticket'] == 'A/5. 851']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedData['FamilyName'] = combinedData.Name.str.extract('(\\w+),', expand = False)\n",
    "trData['FamilyName'] = trData.Name.str.extract('(\\w+),', expand = False)\n",
    "testData['FamilyName'] = testData.Name.str.extract('(\\w+),', expand = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedData['FamilyName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_counts = combinedData['Ticket'].value_counts()\n",
    "ticket_unique = combinedData['Ticket'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_surv_array = []\n",
    "for i in range(0, len(ticket_unique)):\n",
    "    expression1 = (((testData['Ticket'] == ticket_unique[i]).sum() > 0) & (((trData['Ticket'] == ticket_unique[i]).sum()) > 1))\n",
    "    expression2 = (((testData['Ticket'] == ticket_unique[i]).sum() > 0) & (((trData['Ticket'] == ticket_unique[i]).sum()) == 1))\n",
    "    if expression1:\n",
    "        if trData.loc[trData['Ticket'] == ticket_unique[i], 'Survived'].mean() > 0.75:\n",
    "            survival_rate_i =  1\n",
    "        elif 0.5 <= trData.loc[trData['Ticket'] == ticket_unique[i], 'Survived'].mean() <=0.75:\n",
    "            survival_rate_i = 0.5\n",
    "        elif 0.25 <= trData.loc[trData['Ticket'] == ticket_unique[i], 'Survived'].mean() < 0.5:\n",
    "            survival_rate_i = 0.25\n",
    "        else:\n",
    "            survival_rate_i = 0\n",
    "    elif expression2:\n",
    "        survival_rate_i =  0.5 * trData.loc[trData['Ticket'] == ticket_unique[i], 'Survived'].mean()\n",
    "    else:\n",
    "        survival_rate_i = -1\n",
    "    temp_surv_array.append(survival_rate_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myDict = dict(zip(ticket_unique, temp_surv_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    data['TicketSurvivalRate'] = data['Ticket'].apply(lambda x: myDict[x])\n",
    "testData['TicketSurvivalRate'].fillna(0, inplace = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelName = 'FamilyName'\n",
    "family_counts = combinedData[labelName].value_counts()\n",
    "family_unique = combinedData[labelName].value_counts().index\n",
    "temp_surv_array = []\n",
    "for i in range(0, len(family_unique)):\n",
    "    expression1 = (((testData[labelName] == family_unique[i]).sum() > 0) & (((trData[labelName] == family_unique[i]).sum()) > 1))\n",
    "    expression2 = (((testData[labelName] == family_unique[i]).sum() > 0) & (((trData[labelName] == family_unique[i]).sum()) == 1))\n",
    "    if expression1:\n",
    "        if trData.loc[trData[labelName] == family_unique[i], 'Survived'].mean() > 0.75:\n",
    "            survival_rate_i =  1\n",
    "        elif 0.5 <= trData.loc[trData[labelName] == family_unique[i], 'Survived'].mean() <=0.75:\n",
    "            survival_rate_i = 0.5\n",
    "        elif 0.25 <= trData.loc[trData[labelName] == family_unique[i], 'Survived'].mean() < 0.5:\n",
    "            survival_rate_i = 0.25\n",
    "        else:\n",
    "            survival_rate_i = 0\n",
    "    elif expression2:\n",
    "        survival_rate_i =  0.5 * trData.loc[trData[labelName] == family_unique[i], 'Survived'].mean()\n",
    "    else:\n",
    "        survival_rate_i = -1\n",
    "    temp_surv_array.append(survival_rate_i)\n",
    "myDict = dict(zip(family_unique, temp_surv_array))\n",
    "for data in data_list:\n",
    "    data['FamilySurvivalRate'] = data[labelName].apply(lambda x: myDict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'TicketSurvivalRate', y = 'Survived', data = trData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['TicketSurvivalRate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'FamilySurvivalRate', y = 'Survived', data = trData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combinedData.loc[combinedData['FamilyName'] == 'Asplund'][['Name', 'Nfamily', 'Survived','Ticket']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title_vs_age = combinedData[['Title', 'Age']].groupby(['Title'], as_index = False).mean()\n",
    "title_vs_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vs_age.loc[title_vs_age['Title'] == 'Master', 'Age'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_array = []\n",
    "# for data in data_list:\n",
    "#     for i in range(len(data)):\n",
    "#         if np.isnan(data['Age'][i]):\n",
    "#             colVec = (data['Title'] == data['Title'][i]) & (data['Embarked'] == data['Embarked'][i]) & (data['Pclass'] == data['Pclass'][i]) \n",
    "#             temp_array.append(data.loc[colVec, 'Age'].mean())\n",
    "#         else:\n",
    "#             temp_array.append(data['Age'][i])\n",
    "#     data['Age'] = temp_array\n",
    "#     temp_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(title_vs_age)):\n",
    "    title_temp = title_vs_age.loc[i]['Title']\n",
    "    trData.loc[trData['Age'].isnull() & (trData['Title'] == title_temp), 'Age'] = title_vs_age.loc[title_vs_age['Title'] == title_temp, 'Age'][i]\n",
    "    testData.loc[testData['Age'].isnull() & (testData['Title'] == title_temp), 'Age'] = title_vs_age.loc[title_vs_age['Title'] == title_temp, 'Age'][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin code; missing cabin code is converted to 0, and existing ones converted to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    data['CabinCode'] = (data['Cabin'].notnull()) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer categorial values to discrete values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trData['Title'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the age bins and fare bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins = [0, 12, 19, 25, 35, 60, np.inf]\n",
    "age_labels = ['Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "trData['AgeGroup'] = pd.cut(trData[\"Age\"], age_bins, labels = age_labels)\n",
    "testData['AgeGroup'] = pd.cut(testData[\"Age\"], age_bins, labels = age_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['AgeGroup'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'AgeGroup', y = 'Survived', data = trData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(x = 'AgeGroup', y = 'Survived', data = trData.loc[trData['Pclass'] == 1])\n",
    "g.set_title(\"Pclass = 1\")\n",
    "plt.show()\n",
    "g = sns.barplot(x = 'AgeGroup', y = 'Survived', data = trData.loc[trData['Pclass'] == 2])\n",
    "g.set_title(\"Pclass = 2\")\n",
    "plt.show()\n",
    "g = sns.barplot(x = 'AgeGroup', y = 'Survived', data = trData.loc[trData['Pclass'] == 3])\n",
    "g.set_title(\"Pclass = 3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['Fare'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(trData['Fare'], 3).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combinedData[['Pclass','Fare']].groupby(['Pclass'], as_index = False).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['Fare'].describe()\n",
    "fare_bins = [-0.1,  7.5, 15, 40, 70, np.inf]\n",
    "fare_labels = ['Cheap', 'BelowAverage', 'Average', 'AboveAverage','Expensive']\n",
    "trData['FareBin'] = pd.cut(trData['Fare'], fare_bins, labels = fare_labels)\n",
    "testData['FareBin'] = pd.cut(testData['Fare'], fare_bins, labels = fare_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x = 'FareBin', y = 'Survived', data = trData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variation of survival rate vs agegroup within the three Pclasses (this helps picking the right age_bins)\n",
    "g = sns.barplot(x = 'FareBin', y = 'Survived', data = trData.loc[trData['Pclass'] == 1])\n",
    "g.set_title(\"Pclass = 1\")\n",
    "plt.show()\n",
    "g = sns.barplot(x = 'FareBin', y = 'Survived', data = trData.loc[trData['Pclass'] == 2])\n",
    "g.set_title(\"Pclass = 2\")\n",
    "plt.show()\n",
    "g = sns.barplot(x = 'FareBin', y = 'Survived', data = trData.loc[trData['Pclass'] == 3])\n",
    "g.set_title(\"Pclass = 3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(x = 'Embarked', y = 'Survived', data = trData.loc[trData['Pclass'] == 1])\n",
    "g.set_title(\"Pclass = 1\")\n",
    "plt.show()\n",
    "g = sns.barplot(x = 'Embarked', y = 'Survived', data = trData.loc[trData['Pclass'] == 2])\n",
    "g.set_title(\"Pclass = 2\")\n",
    "plt.show()\n",
    "g = sns.barplot(x = 'Embarked', y = 'Survived', data = trData.loc[trData['Pclass'] == 3])\n",
    "g.set_title(\"Pclass = 3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trData['FareBin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TicketVec = []\n",
    "for data in data_list:\n",
    "    for i in list(data.Ticket):\n",
    "        if not i.isdigit() :\n",
    "            TicketVec.append(i.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')[0]) #Take prefix\n",
    "        else:\n",
    "            TicketVec.append(\"X\")\n",
    "    data[\"TicketLetter\"] = TicketVec\n",
    "    data[\"TicketLetter\"].head()\n",
    "    TicketVec = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['TicketLetter'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    data['TicketPrefix'] = data['TicketLetter'].apply(lambda x: 'Rare' if data['TicketLetter'].value_counts()[x] < 6 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testData['TicketPrefix'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['TicketPrefix'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'TicketPrefix', y = 'Survived', data = trData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "for data in data_list:\n",
    "    #data['FareBinCode'] = label.fit_transform(data['FareBin'])\n",
    "    #data['AgeBinCode'] = label.fit_transform(data['AgeBin']) \n",
    "    #data['TicketCode'] = label.fit_transform(data['TicketPrefix'])\n",
    "    data['TicketCode'] = data['TicketPrefix'].replace(['X','Rare', 'PC', 'CA', 'A5', 'SOTONOQ', 'STONO', 'WC', 'SCPARIS', 'A4', 'SOC', 'STONO2']\n",
    "                                                      , [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "    data['SexCode'] = data['Sex'].replace(['female', 'male'], [0, 1])\n",
    "    data['EmbarkedCode'] = data['Embarked'].replace(['S', 'Q', 'C'], [0, 1, 2])\n",
    "    data['TitleCode'] = data['Title'].replace(['Mr', 'Mrs', 'Miss', 'Master','Royal', 'Rare'], [0, 1, 2, 3, 4, 5])\n",
    "    data['IsAlone'] = 1\n",
    "    data.loc[data['Nfamily'] > 1, 'IsAlone'] = 0\n",
    "    data['AgeGroup'] = data['AgeGroup'].replace(age_labels,[0, 1, 2, 3, 4, 5])\n",
    "    data['FareBin'] = data['FareBin'].replace(fare_labels, [0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData[['Nfamily', 'Survived']].groupby(['Nfamily'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trData[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trData[['Sex','Survived']].groupby(['Sex'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trData[['SibSp','Survived']].groupby(['SibSp'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trData['SibSp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trData[['Pclass','Fare','Survived']].groupby(['Pclass'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Pclass\", y=\"Survived\", data=trData)\n",
    "plt.show()\n",
    "sns.barplot(x=\"EmbarkedCode\", y=\"Survived\", data=trData)\n",
    "plt.show()\n",
    "sns.barplot(x = \"CabinCode\", y = \"Survived\", data = trData)\n",
    "plt.show()\n",
    "sns.barplot(x = \"TitleCode\", y = \"Survived\", data = trData)\n",
    "plt.show()\n",
    "sns.barplot(x = \"AgeGroup\", y = \"Survived\", data = trData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(trData['Sex'], trData['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trData[['TitleCode','Survived']].groupby(['TitleCode'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_heatmap(df):\n",
    "    _ , ax = plt.subplots(figsize =(14, 12))\n",
    "    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "    \n",
    "    _ = sns.heatmap(\n",
    "        df.corr(), \n",
    "        cmap = colormap,\n",
    "        square=True, \n",
    "        cbar_kws={'shrink':.9 }, \n",
    "        ax=ax,\n",
    "        annot=True, \n",
    "        linewidths=0.1,vmax=1.0, linecolor='white',\n",
    "        annot_kws={'fontsize':12 }\n",
    "    )\n",
    "    \n",
    "    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "\n",
    "correlation_heatmap(trData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification models, cross-validation, and parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedFeatures = ['Pclass', 'SexCode', 'AgeGroup', 'TitleCode', 'Nfamily', 'IsAlone', 'EmbarkedCode', 'FareBin'\n",
    "                    ,'CabinCode', 'TicketCode', 'TicketSurvivalRate']; # IsAlone is a redundant feature and I think it should be removed, however, with that I got a better submission accuracy on Kaggle\n",
    "X = trData[selectedFeatures]\n",
    "y = trData['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "First a cross validation; we split the training set (trData) to a test size of 20 percent and train size of 0.8. We do a cross validation on 0.8 set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.2, train_size = 0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the above results we try a voting \n",
    "### Comparing different possible voting lists\n",
    "We try different voting lists, and pick the one with the highest accuracy. Once we decide about the best voting list, we run the gridsearchCV this time for the whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting_list = [('grBoost', clf_list[2]), ('randforest', clf_list[3]), ('extree', clf_list[4]), ('knn', clf_list[5])]\n",
    "# # voting_list = [('randforest', clf_list[3]), ('extree', clf_list[4]), ('grBoost', clf_list[2])]\n",
    "# voting_list = [('a', clf_list[2]), ('c', clf_list[3]), ('d', clf_list[3])]\n",
    "# votingC = ensemble.VotingClassifier(estimators=voting_list, voting='soft', n_jobs=4)\n",
    "# votingC = votingC.fit(Xtrain, ytrain)\n",
    "# arpredict = votingC.predict(Xtest)\n",
    "# print(metrics.accuracy_score(ytest, arpredict))\n",
    "# best_voting_list = votingC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above number is the approximated accuracy that we should when testing the real data. However, of course we should use all the available results for fitting so we replace Xtrain and ytrain with X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .4, train_size = .6, random_state = 0) \n",
    "grid_bool = [True, False]\n",
    "C_param_range = [0.001,0.01,0.1,0.2,1,10,11,12,13,20, 30, 40]\n",
    "grid_ratio_list = [.1, .25, .5, .75, 1.0]\n",
    "grid_n_neighbors = range(1, 20)\n",
    "grid_n_estimator = [10, 50, 100, 300]\n",
    "grid_learn = [.01, .03, .05, .1, .25]\n",
    "grid_max_depth = [2, 4, 6, 8, 10, None]\n",
    "grid_min_samples = [5, 10, .03, .05, .10]\n",
    "grid_criterion = ['gini', 'entropy']\n",
    "grid_bool = [True, False]\n",
    "grid_seed = [0]\n",
    "\n",
    "clf_list = [LogisticRegression(), SVC(), ensemble.GradientBoostingClassifier(), ensemble.RandomForestClassifier(), \n",
    "            ensemble.ExtraTreesClassifier(), KNeighborsClassifier()]\n",
    "grid_param_list = [[{\n",
    "            #LogisticRegressionCV - http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV\n",
    "            'fit_intercept': grid_bool, #default: True\n",
    "            #'penalty': ['l1','l2'],\n",
    "            'C': C_param_range,\n",
    "            #'solver': ['newton-cg','lbfgs','liblinear']\n",
    "             }],\n",
    "             [{\n",
    "            'C': C_param_range,\n",
    "             'gamma': grid_ratio_list\n",
    "             }],\n",
    "             [{\n",
    "              'max_depth': grid_max_depth   \n",
    "             }], \n",
    "             [{\n",
    "             'n_estimators': grid_n_estimator, #default=10\n",
    "             'criterion': grid_criterion, #default=”gini”\n",
    "             'max_depth': grid_max_depth, #default=None\n",
    "             #'oob_score': [True],\n",
    "             'random_state': grid_seed\n",
    "             }],\n",
    "             [{\n",
    "             'n_estimators': grid_n_estimator, #default=10\n",
    "             'criterion': grid_criterion, #default=”gini”\n",
    "             'max_depth': grid_max_depth, #default=None\n",
    "             #'oob_score': [True],\n",
    "             'random_state': grid_seed\n",
    "             }],\n",
    "             [{\n",
    "              'n_neighbors': grid_n_neighbors\n",
    "             }]\n",
    "             ]\n",
    "best_scores_list = []\n",
    "for clf, param in zip (clf_list, grid_param_list):\n",
    "    best_search = model_selection.GridSearchCV(estimator = clf, param_grid = param, cv = cv_split, scoring = 'roc_auc'\n",
    "                                              , n_jobs = 4)\n",
    "    best_search.fit(X, y) # Note X, y NOT Xtrain, ytrain\n",
    "    best_param = best_search.best_params_\n",
    "    best_score = best_search.best_score_\n",
    "    print('The best parameter for {} is {} with a runtime of seconds with a score of {}'.format(clf.__class__.__name__, best_param, best_score))\n",
    "    clf.set_params(**best_param) \n",
    "    best_scores_list.append(best_score)\n",
    "print(\"--\"*45, \"\\nMax cross-validation score is:\", max(best_scores_list))\n",
    "print(\"--\"*45, \"\\nAverage cross-validation score is:\", sum(sorted(best_scores_list, reverse=True)[0:3]) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_voting_list = [('a', clf_list[2]), ('c', clf_list[3]), ('d', clf_list[4])]\n",
    "# best_voting_list = [('a', clf_list[2])]\n",
    "votingC = ensemble.VotingClassifier(estimators=best_voting_list, voting='soft', n_jobs=4)\n",
    "votingC = votingC.fit(X, y) # Note we fit the Whole X, y\n",
    "arpredict = votingC.predict(Xtest)\n",
    "print(metrics.accuracy_score(ytest, arpredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataTemp = testData[selectedFeatures]\n",
    "arPredict = votingC.predict(testDataTemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataTemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredict = pd.DataFrame({'PassengerId':testData['PassengerId'], 'Survived': arPredict})\n",
    "yPredict.to_csv('../predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataTemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "now = pd.read_csv('../predictions.csv')\n",
    "best = pd.read_csv('../predictions_score82296.csv')\n",
    "print(len(testData.loc[now['Survived'] != best['Survived']]))\n",
    "testData.loc[now['Survived'] != best['Survived'], ['Ticket', 'Nfamily', 'TicketSurvivalRate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData.loc[trData['Ticket'] == '110813']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.loc[testData['Ticket'] == '110813']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredict.loc[now['Survived'] != best['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
