{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem description\n",
    "This is a kaggle competition where we want to predict the survival of a subset of titanic passenters (test set), given a set of passengers with known survival (train set). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries\n",
    "As the first step all neccessary libraries will be imported; this list will be updated as we are going forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import ensemble, model_selection\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting to know your data\n",
    "As usual the first step is to get to know the data; how many samples, what are the attributes, what are the missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData = pd.read_csv('train.csv')\n",
    "testData = pd.read_csv('test.csv')\n",
    "data_list = [trData, testData]\n",
    "trData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "## The columns which are not numeric will be converted to numeric and the columns with too many NaNs will be removed (e.g., the Cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of samples in train set is:\", len(trData))\n",
    "print(\"-\"*45)\n",
    "print(\"The number of null (NaN) values in each column of the train set is:\")\n",
    "print(trData.isnull().sum())\n",
    "print(\"*\"*70)\n",
    "print(\"Total number of samples in test set is:\", len(testData))\n",
    "print(\"-\"*45)\n",
    "print(\"The number of null (NaN) values in each column of the train set is:\")\n",
    "print(testData.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    #data['Age'].fillna(trData['Age'].median(), inplace = True)\n",
    "    data['Embarked'].fillna(trData['Embarked'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of samples in train set is:\", len(trData))\n",
    "print(\"-\"*45)\n",
    "print(\"The number of null (NaN) values in each column of the train set is:\")\n",
    "print(trData.isnull().sum())\n",
    "print(\"*\"*70)\n",
    "print(\"Total number of samples in test set is:\", len(testData))\n",
    "print(\"-\"*45)\n",
    "print(\"The number of null (NaN) values in each column of the train set is:\")\n",
    "print(testData.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedData = pd.concat(objs=[trData, testData], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PclassVsFare = combinedData[['Pclass','Fare']].groupby(['Pclass'], as_index = False).mean()\n",
    "PclassVsFare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['Pclass'][testData['Fare'].isnull()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The passenger with missing class has a Pclass of 3 whose average Fare is 13.67 \n",
    "testData['Fare'].fillna(PclassVsFare.loc[2,'Fare'], inplace = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    data['Title'] = data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    data['Title'] = data['Title'].replace(['Lady', 'Sir', 'the Countess'], 'Royal')\n",
    "    data['Title'] = data['Title'].replace(['Ms', 'Mlle'], 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
    "    data['Title'] = data['Title'].replace(['Lady', 'Capt', 'Col',\n",
    "    'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    data['Nfamily'] = data['Parch'] + data['SibSp'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedData = pd.concat(objs=[trData, testData], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedData['FamilyName'] = combinedData.Name.str.extract('(\\w+),', expand = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedData['FamilyName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_counts = combinedData['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combinedData['Ticket'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedData['Ticket'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_survival_rate = combinedData['Ticket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_survival_rate[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_surv_array = []\n",
    "for i in range(0, len(ticket_survival_rate)):\n",
    "    if (combinedData['Ticket'].value_counts()[ticket_counts[i]] > 1) & ((testData['Ticket'] == ticket_counts[i]).sum() > 1):\n",
    "        survival_rate_i = trData.loc[trData['Ticket'] == ticket_counts[i], 'Survived'].mean()\n",
    "    else:\n",
    "        survival_rate_i = 0.5\n",
    "    temp_surv_array.append(survival_rate_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myDict = dict(zip(ticket_survival_rate, temp_surv_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    data['TicketSurvivalRate'] = data['Ticket'].apply(lambda x: myDict[x])\n",
    "testData['TicketSurvivalRate'].fillna(0.5, inplace = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'TicketSurvivalRate', y = 'Survived', data = trData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedData.loc[combinedData['FamilyName'] == 'Asplund'][['Name', 'Nfamily', 'Survived','Ticket']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title_vs_age = combinedData[['Title', 'Age']].groupby(['Title'], as_index = False).mean()\n",
    "title_vs_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vs_age.loc[title_vs_age['Title'] == 'Master', 'Age'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_array = []\n",
    "# for data in data_list:\n",
    "#     for i in range(len(data)):\n",
    "#         if np.isnan(data['Age'][i]):\n",
    "#             colVec = (data['Title'] == data['Title'][i]) & (data['Embarked'] == data['Embarked'][i]) & (data['Pclass'] == data['Pclass'][i]) \n",
    "#             temp_array.append(data.loc[colVec, 'Age'].mean())\n",
    "#         else:\n",
    "#             temp_array.append(data['Age'][i])\n",
    "#     data['Age'] = temp_array\n",
    "#     temp_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(title_vs_age)):\n",
    "    title_temp = title_vs_age.loc[i]['Title']\n",
    "    trData.loc[trData['Age'].isnull() & (trData['Title'] == title_temp), 'Age'] = title_vs_age.loc[title_vs_age['Title'] == title_temp, 'Age'][i]\n",
    "    testData.loc[testData['Age'].isnull() & (testData['Title'] == title_temp), 'Age'] = title_vs_age.loc[title_vs_age['Title'] == title_temp, 'Age'][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin code; missing cabin code is converted to 0, and existing ones converted to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    data['CabinCode'] = (data['Cabin'].notnull()) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer categorial values to discrete values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trData['Title'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the age bins and fare bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins = [0, 12, 19, 25, 35, 60, np.inf]\n",
    "age_labels = ['Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "trData['AgeGroup'] = pd.cut(trData[\"Age\"], age_bins, labels = age_labels)\n",
    "testData['AgeGroup'] = pd.cut(testData[\"Age\"], age_bins, labels = age_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['AgeGroup'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'AgeGroup', y = 'Survived', data = trData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(x = 'AgeGroup', y = 'Survived', data = trData.loc[trData['Pclass'] == 1])\n",
    "g.set_title(\"Pclass = 1\")\n",
    "plt.show()\n",
    "g = sns.barplot(x = 'AgeGroup', y = 'Survived', data = trData.loc[trData['Pclass'] == 2])\n",
    "g.set_title(\"Pclass = 2\")\n",
    "plt.show()\n",
    "g = sns.barplot(x = 'AgeGroup', y = 'Survived', data = trData.loc[trData['Pclass'] == 3])\n",
    "g.set_title(\"Pclass = 3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['Fare'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(trData['Fare'], 3).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combinedData[['Pclass','Fare']].groupby(['Pclass'], as_index = False).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['Fare'].describe()\n",
    "fare_bins = [-0.1,  7.5, 15, 40, 70, np.inf]\n",
    "fare_labels = ['Cheap', 'BelowAverage', 'Average', 'AboveAverage','Expensive']\n",
    "trData['FareBin'] = pd.cut(trData['Fare'], fare_bins, labels = fare_labels)\n",
    "testData['FareBin'] = pd.cut(testData['Fare'], fare_bins, labels = fare_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x = 'FareBin', y = 'Survived', data = trData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variation of survival rate vs agegroup within the three Pclasses (this helps picking the right age_bins)\n",
    "g = sns.barplot(x = 'FareBin', y = 'Survived', data = trData.loc[trData['Pclass'] == 1])\n",
    "g.set_title(\"Pclass = 1\")\n",
    "plt.show()\n",
    "g = sns.barplot(x = 'FareBin', y = 'Survived', data = trData.loc[trData['Pclass'] == 2])\n",
    "g.set_title(\"Pclass = 2\")\n",
    "plt.show()\n",
    "g = sns.barplot(x = 'FareBin', y = 'Survived', data = trData.loc[trData['Pclass'] == 3])\n",
    "g.set_title(\"Pclass = 3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(x = 'Embarked', y = 'Survived', data = trData.loc[trData['Pclass'] == 1])\n",
    "g.set_title(\"Pclass = 1\")\n",
    "plt.show()\n",
    "g = sns.barplot(x = 'Embarked', y = 'Survived', data = trData.loc[trData['Pclass'] == 2])\n",
    "g.set_title(\"Pclass = 2\")\n",
    "plt.show()\n",
    "g = sns.barplot(x = 'Embarked', y = 'Survived', data = trData.loc[trData['Pclass'] == 3])\n",
    "g.set_title(\"Pclass = 3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trData['FareBin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TicketVec = []\n",
    "for data in data_list:\n",
    "    for i in list(data.Ticket):\n",
    "        if not i.isdigit() :\n",
    "            TicketVec.append(i.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')[0]) #Take prefix\n",
    "        else:\n",
    "            TicketVec.append(\"X\")\n",
    "    data[\"TicketLetter\"] = TicketVec\n",
    "    data[\"TicketLetter\"].head()\n",
    "    TicketVec = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['TicketLetter'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    data['TicketPrefix'] = data['TicketLetter'].apply(lambda x: 'Rare' if data['TicketLetter'].value_counts()[x] < 6 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testData['TicketPrefix'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData['TicketPrefix'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'TicketPrefix', y = 'Survived', data = trData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "for data in data_list:\n",
    "    #data['FareBinCode'] = label.fit_transform(data['FareBin'])\n",
    "    #data['AgeBinCode'] = label.fit_transform(data['AgeBin']) \n",
    "    #data['TicketCode'] = label.fit_transform(data['TicketPrefix'])\n",
    "    data['TicketCode'] = data['TicketPrefix'].replace(['X','Rare', 'PC', 'CA', 'A5', 'SOTONOQ', 'STONO', 'WC', 'SCPARIS', 'A4', 'SOC', 'STONO2']\n",
    "                                                      , [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "    data['SexCode'] = data['Sex'].replace(['female', 'male'], [0, 1])\n",
    "    data['EmbarkedCode'] = data['Embarked'].replace(['S', 'Q', 'C'], [0, 1, 2])\n",
    "    data['TitleCode'] = data['Title'].replace(['Mr', 'Mrs', 'Miss', 'Master','Royal', 'Rare'], [0, 1, 2, 3, 4, 5])\n",
    "    data['IsAlone'] = 1\n",
    "    data.loc[data['Nfamily'] > 1, 'IsAlone'] = 0\n",
    "    data['AgeGroup'] = data['AgeGroup'].replace(age_labels,[0, 1, 2, 3, 4, 5])\n",
    "    data['FareBin'] = data['FareBin'].replace(fare_labels, [0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trData[['Nfamily', 'Survived']].groupby(['Nfamily'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trData[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trData[['Sex','Survived']].groupby(['Sex'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trData[['SibSp','Survived']].groupby(['SibSp'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trData['SibSp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trData[['Pclass','Fare','Survived']].groupby(['Pclass'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Pclass\", y=\"Survived\", data=trData)\n",
    "plt.show()\n",
    "sns.barplot(x=\"EmbarkedCode\", y=\"Survived\", data=trData)\n",
    "plt.show()\n",
    "sns.barplot(x = \"CabinCode\", y = \"Survived\", data = trData)\n",
    "plt.show()\n",
    "sns.barplot(x = \"TitleCode\", y = \"Survived\", data = trData)\n",
    "plt.show()\n",
    "sns.barplot(x = \"AgeGroup\", y = \"Survived\", data = trData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(trData['Sex'], trData['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trData[['TitleCode','Survived']].groupby(['TitleCode'], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_heatmap(df):\n",
    "    _ , ax = plt.subplots(figsize =(14, 12))\n",
    "    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "    \n",
    "    _ = sns.heatmap(\n",
    "        df.corr(), \n",
    "        cmap = colormap,\n",
    "        square=True, \n",
    "        cbar_kws={'shrink':.9 }, \n",
    "        ax=ax,\n",
    "        annot=True, \n",
    "        linewidths=0.1,vmax=1.0, linecolor='white',\n",
    "        annot_kws={'fontsize':12 }\n",
    "    )\n",
    "    \n",
    "    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "\n",
    "correlation_heatmap(trData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification models, cross-validation, and parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedFeatures = ['Pclass', 'SexCode', 'AgeGroup', 'TitleCode', 'Nfamily', 'IsAlone', 'EmbarkedCode', 'FareBin'\n",
    "                    ,'CabinCode', 'TicketCode']; # IsAlone is a redundant feature and I think it should be removed, however, with that I got a better submission accuracy on Kaggle\n",
    "X = trData[selectedFeatures]\n",
    "y = trData['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "First a cross validation; we split the training set (trData) to a test size of 20 percent and train size of 0.8. We do a cross validation on 0.8 set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.2, train_size = 0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the above results we try a voting \n",
    "### Comparing different possible voting lists\n",
    "We try different voting lists, and pick the one with the highest accuracy. Once we decide about the best voting list, we run the gridsearchCV this time for the whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting_list = [('grBoost', clf_list[2]), ('randforest', clf_list[3]), ('extree', clf_list[4]), ('knn', clf_list[5])]\n",
    "# # voting_list = [('randforest', clf_list[3]), ('extree', clf_list[4]), ('grBoost', clf_list[2])]\n",
    "# voting_list = [('a', clf_list[2]), ('c', clf_list[3]), ('d', clf_list[3])]\n",
    "# votingC = ensemble.VotingClassifier(estimators=voting_list, voting='soft', n_jobs=4)\n",
    "# votingC = votingC.fit(Xtrain, ytrain)\n",
    "# arpredict = votingC.predict(Xtest)\n",
    "# print(metrics.accuracy_score(ytest, arpredict))\n",
    "# best_voting_list = votingC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above number is the approximated accuracy that we should when testing the real data. However, of course we should use all the available results for fitting so we replace Xtrain and ytrain with X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .4, train_size = .6, random_state = 0) \n",
    "grid_bool = [True, False]\n",
    "C_param_range = [0.001,0.01,0.1,0.2,1,10,11,12,13,20, 30, 40]\n",
    "grid_ratio_list = [.1, .25, .5, .75, 1.0]\n",
    "grid_n_neighbors = range(1, 20)\n",
    "grid_n_estimator = [10, 50, 100, 300]\n",
    "grid_learn = [.01, .03, .05, .1, .25]\n",
    "grid_max_depth = [2, 4, 6, 8, 10, None]\n",
    "grid_min_samples = [5, 10, .03, .05, .10]\n",
    "grid_criterion = ['gini', 'entropy']\n",
    "grid_bool = [True, False]\n",
    "grid_seed = [0]\n",
    "\n",
    "clf_list = [LogisticRegression(), SVC(), ensemble.GradientBoostingClassifier(), ensemble.RandomForestClassifier(), \n",
    "            ensemble.ExtraTreesClassifier(), KNeighborsClassifier()]\n",
    "grid_param_list = [[{\n",
    "            #LogisticRegressionCV - http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV\n",
    "            'fit_intercept': grid_bool, #default: True\n",
    "            #'penalty': ['l1','l2'],\n",
    "            'C': C_param_range,\n",
    "            #'solver': ['newton-cg','lbfgs','liblinear']\n",
    "             }],\n",
    "             [{\n",
    "            'C': C_param_range,\n",
    "             'gamma': grid_ratio_list\n",
    "             }],\n",
    "             [{\n",
    "              'max_depth': grid_max_depth   \n",
    "             }], \n",
    "             [{\n",
    "             'n_estimators': grid_n_estimator, #default=10\n",
    "             'criterion': grid_criterion, #default=”gini”\n",
    "             'max_depth': grid_max_depth, #default=None\n",
    "             #'oob_score': [True],\n",
    "             'random_state': grid_seed\n",
    "             }],\n",
    "             [{\n",
    "             'n_estimators': grid_n_estimator, #default=10\n",
    "             'criterion': grid_criterion, #default=”gini”\n",
    "             'max_depth': grid_max_depth, #default=None\n",
    "             #'oob_score': [True],\n",
    "             'random_state': grid_seed\n",
    "             }],\n",
    "             [{\n",
    "              'n_neighbors': grid_n_neighbors\n",
    "             }]\n",
    "             ]\n",
    "best_scores_list = []\n",
    "for clf, param in zip (clf_list, grid_param_list):\n",
    "    best_search = model_selection.GridSearchCV(estimator = clf, param_grid = param, cv = cv_split, scoring = 'roc_auc'\n",
    "                                              , n_jobs = 4)\n",
    "    best_search.fit(X, y) # Note X, y NOT Xtrain, ytrain\n",
    "    best_param = best_search.best_params_\n",
    "    best_score = best_search.best_score_\n",
    "    print('The best parameter for {} is {} with a runtime of seconds with a score of {}'.format(clf.__class__.__name__, best_param, best_score))\n",
    "    clf.set_params(**best_param) \n",
    "    best_scores_list.append(best_score)\n",
    "print(\"--\"*45, \"\\nMax cross-validation score is:\", max(best_scores_list))\n",
    "print(\"--\"*45, \"\\nAverage cross-validation score is:\", sum(sorted(best_scores_list, reverse=True)[0:3]) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_voting_list = [('a', clf_list[2]), ('c', clf_list[3]), ('d', clf_list[4])]\n",
    "votingC = ensemble.VotingClassifier(estimators=best_voting_list, voting='soft', n_jobs=4)\n",
    "votingC = votingC.fit(X, y) # Note we fit the Whole X, y\n",
    "arpredict = votingC.predict(Xtest)\n",
    "print(metrics.accuracy_score(ytest, arpredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataTemp = testData[selectedFeatures]\n",
    "arPredict = votingC.predict(testDataTemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataTemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredict = pd.DataFrame({'PassengerId':testData['PassengerId'], 'Survived': arPredict})\n",
    "yPredict.to_csv('../predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataTemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "now = pd.read_csv('../predictions.csv')\n",
    "best = pd.read_csv('../predictions_score80382.csv')\n",
    "print(len(testData.loc[now['Survived'] != best['Survived']]))\n",
    "testData.loc[now['Survived'] != best['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
